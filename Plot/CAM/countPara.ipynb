{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108,461 total parameters.\n",
      "0.10M total parameters.\n",
      "104,962 training parameters.\n",
      "0.10M training parameters.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from wfdb import processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "model = torch.load('./net1d.pth', map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params += sum(p.numel() for p in model.buffers())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "print(f'{total_params/(1024*1024):.2f}M total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')\n",
    "print(f'{total_trainable_params/(1024*1024):.2f}M training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.06291341781616211 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "model = torch.load('./net1d.pth', map_location=torch.device('cpu'))\n",
    "model.eval()\n",
    "\n",
    "input_image = torch.randn(32, 1, 200)  # 3-channel, 224x224 image\n",
    "\n",
    "# Perform model inference and calculate the inference time\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    output = model(input_image)\n",
    "    end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference Time: {inference_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
